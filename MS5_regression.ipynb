{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3322c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4fffc33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eed7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac6d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, randrange, sample\n",
    "\n",
    "\n",
    "def mix_augument(np_x, np_y, item_num = 10, drop_out = 0):\n",
    "    aug_x = np.zeros((item_num, np_x.shape[1]))\n",
    "    aug_y = np.zeros(item_num)\n",
    "    for i in range(item_num):\n",
    "        aug = sample(range(np_x.shape[0]), k=2)\n",
    "        mask_a = np.ones(np_x.shape[1])\n",
    "        mask_b = np.ones(np_x.shape[1])\n",
    "        num_drop = int(np_x.shape[1] * drop_out)\n",
    "        mask_a[:num_drop] = 0\n",
    "        mask_b[:num_drop] = 0\n",
    "        np.random.shuffle(mask_a)\n",
    "        np.random.shuffle(mask_b)\n",
    "        a = aug[0]\n",
    "        b = aug[1]\n",
    "        #print(f'{a}{b}')\n",
    "        wa = random()\n",
    "        wb = 1-wa\n",
    "        #print(b)\n",
    "        np_a = np_x[a,:] \n",
    "        np_b = np_x[b,:] \n",
    "        aug_x[i] = wa*np_a*mask_a + wb*np_b*mask_b\n",
    "        aug_y[i] = wa*np_y[a] + wb*np_y[b]\n",
    "        # print(mask_a)\n",
    "        # plt.figure(1)\n",
    "        # plt.plot(np_mass_features_ms5, np_a)\n",
    "        # plt.ylim((0,1))\n",
    "        # plt.show()\n",
    "        # plt.figure(2)\n",
    "        # plt.ylim((0,1))\n",
    "        # plt.plot(np_mass_features_ms5, np_a*mask_a)\n",
    "        # plt.show()\n",
    "        # plt.figure(3)\n",
    "        # plt.plot(np_mass_features_ms5, np_b)\n",
    "        # plt.ylim((0,1))\n",
    "        # plt.show()\n",
    "        # plt.figure(4)\n",
    "        # plt.ylim((0,1))\n",
    "        # plt.plot(np_mass_features_ms5, np_b*mask_b)\n",
    "        # plt.show()\n",
    "        # plt.figure()\n",
    "        # plt.ylim((0,1))\n",
    "        # plt.plot(np_mass_features_ms5, aug_x[i] / max(aug_x[i]))\n",
    "        # plt.show()\n",
    "    aug_x = np.concatenate((np_x, aug_x))\n",
    "    aug_y = np.concatenate((np_y, aug_y))\n",
    "    return aug_x, aug_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa92da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_NIST = ['G2S1(6)', 'G2S2(6)', 'G2FS1(6)', 'G2FS2(6)','G2FS2(6)_REDO','G2S2(3)', 'G2FS2(3)']\n",
    "datasets_NIST_train = ['G2S1(6)', 'G2S2(6)', 'G2FS1(6)', 'G2FS2(6)_REDO','G2S2(3)', 'G2FS2(3)']\n",
    "datasets_NIST_old = ['G2S1(6)', 'G2S2(6)', 'G2FS1(6)', 'G2FS2(6)','G2S2(3)', 'G2FS2(3)']\n",
    "datasets_SL = ['SL']\n",
    "datasets_Released = ['ControlFetuin', 'ControlTransferrin','Alpha.2,3Neur.Fetuin']\n",
    "def load_datasets(datasets, option = '', level = 'MS5'):\n",
    "    if option:\n",
    "        option = option + '_'\n",
    "    if level == 'MS5':\n",
    "        resolution = 10000\n",
    "    else:\n",
    "        resolution = 23000\n",
    "    np_input = np.empty(shape=[resolution,0])\n",
    "    np_output = np.empty(shape=[0])\n",
    "    df_metadata = pd.DataFrame()\n",
    "    for currd in datasets:\n",
    "        path = f'data\\\\test_{option}{currd}_{level}'\n",
    "        # NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "        try: \n",
    "            df_input = pd.read_csv(path + '\\\\' + 'input.csv', header = None)\n",
    "            df_output = pd.read_csv(path + '\\\\' +'output.csv', header = None)\n",
    "            df_currmeta = pd.read_csv(path+'\\\\'+'metadata.csv', header=None, skiprows=1)\n",
    "        except Exception as E:\n",
    "            print(f'Error loading {currd}')\n",
    "            print(E)\n",
    "            continue\n",
    "        df_currmeta[4] = currd\n",
    "        if currd in datasets_NIST:\n",
    "            df_currmeta[5] = 'NIST'\n",
    "        elif currd in datasets_Released:\n",
    "            df_currmeta[5] = 'UGA-R'\n",
    "        else:\n",
    "            df_currmeta[5] = 'UGA-S'\n",
    "        df_metadata = pd.concat((df_metadata, df_currmeta))\n",
    "        df_mass_features_ms5 = pd.read_csv(path + '\\\\' +'mass_features.csv', header = None)\n",
    "        np_mass_features_ms5 = df_mass_features_ms5.to_numpy()\n",
    "        np_mass_features_ms5 = np_mass_features_ms5.reshape(-1)\n",
    "        np_input_curr = df_input.to_numpy()\n",
    "        np_output_curr = df_output.to_numpy()\n",
    "        np_output_curr = np_output_curr.T\n",
    "        np_output_curr = np_output_curr.reshape(-1)\n",
    "        np_input = np.append(np_input, np_input_curr, axis=1)\n",
    "        np_output = np.append(np_output, np_output_curr)\n",
    "    return np_input, np_output, np_mass_features_ms5,df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4d29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_augument_2(np_x, np_y, item_num = 10, drop_out = 0):\n",
    "    aug_x = None\n",
    "    aug_y = None\n",
    "    item_num_ratio = int(item_num / 5)\n",
    "    ratio_list = [0, 0.1, 0.5, 0.9, 1]\n",
    "    for ratio in ratio_list:\n",
    "        idx = np_y == ratio\n",
    "        ratio_x = np_x[idx, :]\n",
    "        ratio_y = np_y[idx]\n",
    "        aug_ratio_x, aug_ratio_y = mix_augument(ratio_x, ratio_y, item_num= item_num_ratio, drop_out=drop_out)\n",
    "        aug_ratio_y = np.ones(len(aug_ratio_y)) * ratio\n",
    "        if aug_x is None:\n",
    "            aug_x = aug_ratio_x\n",
    "        else:\n",
    "            aug_x = np.concatenate((aug_x, aug_ratio_x))\n",
    "        if aug_y is None:\n",
    "            aug_y = aug_ratio_y\n",
    "        else:\n",
    "            aug_y = np.concatenate((aug_y, aug_ratio_y))\n",
    "\n",
    "    return aug_x, aug_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94eaa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_augument(np_x, np_y, item_num = 10, drop_out = 0):\n",
    "    aug = sample(range(np_x.shape[0]), k=item_num)\n",
    "    aug_x = np_x[aug, :]\n",
    "    aug_y = np_y[aug]\n",
    "    aug_x = np.concatenate((np_x, aug_x))\n",
    "    aug_y = np.concatenate((np_y, aug_y))\n",
    "    return aug_x, aug_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b576add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_ratio(np_x, np_y, **args):\n",
    "    aug_x = None\n",
    "    aug_y = None\n",
    "    ratio_list = [0, 0.1, 0.5, 0.9, 1, -1]\n",
    "    for ratio in ratio_list:\n",
    "        idx = np_y == ratio\n",
    "        ratio_x = np_x[idx, :]\n",
    "        ratio_y = np_y[idx]\n",
    "        if aug_x is None:\n",
    "            aug_x = ratio_x\n",
    "        else:\n",
    "            aug_x = np.concatenate((aug_x, ratio_x))\n",
    "        if aug_y is None:\n",
    "            aug_y = ratio_y\n",
    "        else:\n",
    "            aug_y = np.concatenate((aug_y, ratio_y))\n",
    "\n",
    "    return aug_x, aug_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec0ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_score(true_value, predict):\n",
    "    #predict = 1/(1+np.exp(-predict))\n",
    "    predict = np.clip(predict,0,1)\n",
    "    return -mean_squared_error(true_value, predict, squared=False)\n",
    "my_scorer = make_scorer(customize_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9602da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalized_NMF(NMF):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_components=None,\n",
    "        *,\n",
    "        init=\"warn\",\n",
    "        solver=\"cd\",\n",
    "        beta_loss=\"frobenius\",\n",
    "        tol=1e-4,\n",
    "        max_iter=200,\n",
    "        random_state=None,\n",
    "        alpha=\"deprecated\",\n",
    "        alpha_W=0.0,\n",
    "        alpha_H=\"same\",\n",
    "        l1_ratio=0.0,\n",
    "        verbose=0,\n",
    "        shuffle=False,\n",
    "        regularization=\"deprecated\",\n",
    "        normalized = 0,\n",
    "    ):\n",
    "        self.n_components = n_components\n",
    "        self.init = init\n",
    "        self.solver = solver\n",
    "        self.beta_loss = beta_loss\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.alpha = alpha\n",
    "        self.alpha_W = alpha_W\n",
    "        self.alpha_H = alpha_H\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.verbose = verbose\n",
    "        self.shuffle = shuffle\n",
    "        self.regularization = regularization\n",
    "        self.normalized = normalized\n",
    "\n",
    "\n",
    "    \n",
    "    def transform(self, X):\n",
    "        W = super().transform(X) # n x l\n",
    "        X_est = super().inverse_transform(W) # n x m\n",
    "        if self.normalized > 0:\n",
    "            X_max = np.max(X_est, axis = 1) # n x 1\n",
    "            X_max[X_max < self.normalized] = 1\n",
    "            W = np.nan_to_num(W / X_max[:, np.newaxis])\n",
    "        return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8add1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    ('logT', FunctionTransformer(np.log1p)),\n",
    "    ('Norm', Normalizer()),\n",
    "])\n",
    "\n",
    "outlier_pipeline = Pipeline([\n",
    "    # ('logT', FunctionTransformer(np.log1p)),\n",
    "    # ('Norm', Normalizer()),\n",
    "    ('NMF',NMF(2, random_state=42, max_iter=100000, init = 'nndsvd'))\n",
    "])\n",
    "\n",
    "regressor_pipeline = Pipeline([\n",
    "    ('Standardlize', StandardScaler(with_mean=True)),\n",
    "    #('PCA', PCA()),\n",
    "    #('var', VarianceThreshold(threshold=0.001)),\n",
    "    #('select', SelectPercentile(score_func=f_regression, percentile = 80)),\n",
    "    #('pca', PCA()),\n",
    "    ('LR', LinearSVR(random_state = 42, fit_intercept=True, max_iter=100000))]\n",
    ")\n",
    "\n",
    "\n",
    "# exported_pipeline = make_pipeline(\n",
    "# #     StackingEstimator(estimator=DecisionTreeRegressor(max_depth=7, min_samples_leaf=4, min_samples_split=18)),\n",
    "#     Normalizer(norm=\"max\"),\n",
    "#     VarianceThreshold(threshold=0.005),\n",
    "# #     RobustScaler(),\n",
    "#     SelectPercentile(score_func=f_regression, percentile=37),\n",
    "#     LinearSVR(C=1.0, dual=True, epsilon=0.0001, loss=\"epsilon_insensitive\", tol=0.0001, max_iter = 10000)\n",
    "# )\n",
    "\n",
    "#exported_pipeline.fit(np_input, np_output)\n",
    "#results = exported_pipeline.predict(np_input)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ad9af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    # \"var__threshold\": np.linspace(0.0001, 0.01, 5),\n",
    "    # \"select__percentile\": np.linspace(10, 100, 5),\n",
    "    #'pca__n_components': [5, 10, 15, 20, 25],\n",
    "    # 'model__eta': [0.1,0.2,0.3],\n",
    "    # 'model__max_depth': [2,3],\n",
    "    #'model__gamma': [0, 1, 2],\n",
    "    #'model__n_estimators': [500],\n",
    "    #'model__reg_alpha':[ 0,0.1,0.2,0.3],\n",
    "    #'model__reg_lambda':[0,0.1,0.2,0.3]\n",
    "    # 'model__colsample_bytree': [0.3,0.7,1],\n",
    "    \n",
    "#     \"variancethreshold__threshold\": np.linspace(0.0001, 0.01, 20),\n",
    "#     \"selectpercentile__percentile\": np.linspace(10, 100, 10),\n",
    "    # \"PCA__n_components\": [2,3,4,8,16],\n",
    "    # \"NMF__n_components\": [2,4,8],\n",
    "    #\"NMF__normalized\": [0, 0.8],\n",
    "    \"LR__fit_intercept\": [True, False],\n",
    "    \"Standardlize__with_mean\": [True, False],\n",
    " #   \"NMF__alpha_H\": [0, 0.001],\n",
    " #   \"NMF__alpha_W\": [0, 0.001],\n",
    " #   \"LR__C\": [0.1,0.5,1],\n",
    " #   \"LR__epsilon\": [0.001,0.01,0.1,0],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7430fe8c",
   "metadata": {},
   "source": [
    "## Mask non-theoretical peaks\n",
    "* a2-3 signature peaks: 103.08, 131.07\n",
    "* a2-6 signature peaks: 89.06, 117.06"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9e3e224",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7b4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_threshold = 0.8\n",
    "test_threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b3bc0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL -> NIST\n",
      "training set samples:78 test set samples:73\n",
      "A30 | rmse: 0.043\n",
      "A35 | rmse: 0.104\n",
      "A40 | rmse: 0.053\n",
      "A45 | rmse: 0.040\n",
      "A50 | rmse: 0.088\n",
      "B30 | rmse: 0.060\n",
      "B35 | rmse: 0.130\n",
      "B40 | rmse: 0.019\n",
      "B45 | rmse: 0.002\n",
      "B50 | rmse: 0.055\n",
      "C30 | rmse: 0.092\n",
      "C35 | rmse: 0.111\n",
      "C40 | rmse: 0.012\n",
      "C45 | rmse: 0.061\n",
      "C50 | rmse: 0.034\n",
      "all | rmse: 0.072\n",
      "ground truth: 0 | prediction variance: 0.005\n",
      "ground truth: 1 | prediction variance: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Inter-dataset prediction\n",
    "SL_NIST_rmse = []\n",
    "print('SL -> NIST')\n",
    "test_x, test_y, _,test_meta = load_datasets(datasets_NIST, 'NMF_template')\n",
    "train_x, train_y, mass_features,train_meta = load_datasets(datasets_SL)\n",
    "p_x = train_x\n",
    "scalery = StandardScaler()\n",
    "train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "# outlier detection for training set\n",
    "outlier_pipeline.fit(np.concatenate((train_x.T, test_x.T)))\n",
    "W_x = outlier_pipeline.transform(train_x.T)\n",
    "est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "cs_x = cosine_similarity(est_x, train_x.T)\n",
    "weight_x = cs_x.diagonal()\n",
    "idx = weight_x > train_threshold\n",
    "SL_NIST_train_idx = idx\n",
    "train_x = W_x[idx,:]\n",
    "train_y = train_y[idx]\n",
    "train_meta = train_meta.iloc[idx]\n",
    "# outlier detection for test set\n",
    "W_x = outlier_pipeline.transform(test_x.T)\n",
    "est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "cs_x = cosine_similarity(est_x, test_x.T)\n",
    "weight_x = cs_x.diagonal()\n",
    "clip = weight_x > test_threshold\n",
    "SL_NIST_test_idx = clip\n",
    "test_x = W_x[clip,:]\n",
    "test_y = test_y[clip]\n",
    "test_meta = test_meta.iloc[clip]\n",
    "model = regressor_pipeline.fit(train_x, scalery.fit_transform(train_y.reshape((-1,1))).reshape(-1))\n",
    "print(f'training set samples:{train_x.shape[0]} test set samples:{test_x.shape[0]}')\n",
    "from collections import defaultdict\n",
    "pred_dict = defaultdict(lambda : [])\n",
    "gt_dict = defaultdict(lambda : [])\n",
    "pred = np.clip(scalery.inverse_transform(model.predict(test_x).reshape((-1,1))), 0, 1)\n",
    "for i in range(pred.shape[0]):\n",
    "    key = test_meta.iloc[i][0] + str(test_meta.iloc[i][2])\n",
    "    pred_dict[key].append(pred[i])\n",
    "    gt_dict[key].append(test_y[i])\n",
    "isolation_window = ['A', 'B', 'C']\n",
    "energy_level = [30 , 35, 40, 45, 50]\n",
    "all_pred = []\n",
    "all_gt = []\n",
    "for (i, iw) in enumerate(isolation_window):\n",
    "    for (j, el) in enumerate(energy_level):\n",
    "        key = iw + str(el)\n",
    "        # print(key)\n",
    "        rmse = mean_squared_error(pred_dict[key], gt_dict[key], squared=False)\n",
    "        # f1 = f1_score(pred_dict[key], gt_dict[key])\n",
    "        print(f'{iw}{el} | rmse: {\"%.3f\" % rmse}')\n",
    "        SL_NIST_rmse.append(rmse)\n",
    "        all_pred = all_pred + pred_dict[key]\n",
    "        all_gt = all_gt + gt_dict[key]\n",
    "\n",
    "rmse = mean_squared_error(all_pred, all_gt, squared = False)\n",
    "# f1 = f1_score(all_pred, all_gt)\n",
    "print(f'all | rmse: {\"%.3f\" % rmse}')\n",
    "SL_NIST_rmse.append(rmse)\n",
    "for gt in [0, 0.1, 0.5, 0.9, 1]:\n",
    "    idx = np.array(all_gt) == gt\n",
    "    if idx.any():\n",
    "        print(f'ground truth: {gt} | prediction variance: {\"%.3f\" % np.var(np.array(all_pred)[idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f228f61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIST -> SL\n",
      "training set samples:81 test set samples:78\n",
      "A30 | rmse: 0.074\n",
      "A35 | rmse: 0.060\n",
      "A40 | rmse: 0.064\n",
      "A45 | rmse: 0.050\n",
      "A50 | rmse: 0.058\n",
      "B30 | rmse: 0.077\n",
      "B35 | rmse: 0.057\n",
      "B40 | rmse: 0.053\n",
      "B45 | rmse: 0.054\n",
      "B50 | rmse: 0.053\n",
      "C30 | rmse: 0.081\n",
      "C35 | rmse: 0.058\n",
      "C40 | rmse: 0.056\n",
      "C45 | rmse: 0.058\n",
      "C50 | rmse: 0.054\n",
      "all | rmse: 0.061\n",
      "ground truth: 0 | prediction std: 0.006\n",
      "ground truth: 0.1 | prediction std: 0.012\n",
      "ground truth: 0.5 | prediction std: 0.021\n",
      "ground truth: 0.9 | prediction std: 0.006\n",
      "ground truth: 1 | prediction std: 0.002\n"
     ]
    }
   ],
   "source": [
    "# Inter-dataset prediction\n",
    "print('NIST -> SL')\n",
    "test_x, test_y, _,test_meta = load_datasets(datasets_SL, 'NMF_template')\n",
    "train_x, train_y, _,train_meta = load_datasets(datasets_NIST_train)\n",
    "scalery = StandardScaler()\n",
    "train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "# outlier detection for training set\n",
    "outlier_pipeline.fit(np.concatenate((train_x.T, test_x.T)))\n",
    "W_x = outlier_pipeline.transform(train_x.T)\n",
    "est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "cs_x = cosine_similarity(est_x, train_x.T)\n",
    "weight_x = cs_x.diagonal()\n",
    "idx = weight_x > train_threshold\n",
    "train_x = W_x[idx,:]\n",
    "train_y = train_y[idx]\n",
    "train_meta = train_meta.iloc[idx]\n",
    "# outlier detection for test set\n",
    "W_x = outlier_pipeline.transform(test_x.T)\n",
    "est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "cs_x = cosine_similarity(est_x, test_x.T)\n",
    "weight_x = cs_x.diagonal()\n",
    "clip = weight_x > test_threshold\n",
    "test_x = W_x[clip,:]\n",
    "test_y = test_y[clip]\n",
    "test_meta = test_meta.iloc[clip]\n",
    "model = regressor_pipeline.fit(train_x, scalery.fit_transform(train_y.reshape((-1,1))).reshape(-1))\n",
    "print(f'training set samples:{train_x.shape[0]} test set samples:{test_x.shape[0]}')\n",
    "from collections import defaultdict\n",
    "pred_dict = defaultdict(lambda : [])\n",
    "gt_dict = defaultdict(lambda : [])\n",
    "pred = np.clip(scalery.inverse_transform(model.predict(test_x).reshape((-1,1))), 0, 1)\n",
    "for i in range(pred.shape[0]):\n",
    "    key = test_meta.iloc[i][0] + str(test_meta.iloc[i][2])\n",
    "    pred_dict[key].append(pred[i])\n",
    "    gt_dict[key].append(test_y[i])\n",
    "isolation_window = ['A', 'B', 'C']\n",
    "energy_level = [30 , 35, 40, 45, 50]\n",
    "all_pred = []\n",
    "all_gt = []\n",
    "for (i, iw) in enumerate(isolation_window):\n",
    "    for (j, el) in enumerate(energy_level):\n",
    "        key = iw + str(el)\n",
    "        # print(key)\n",
    "        rmse = mean_squared_error(pred_dict[key], gt_dict[key], squared=False)\n",
    "        # f1 = f1_score(pred_dict[key], gt_dict[key])\n",
    "        print(f'{iw}{el} | rmse: {\"%.3f\" % rmse}')\n",
    "        all_pred = all_pred + pred_dict[key]\n",
    "        all_gt = all_gt + gt_dict[key]\n",
    "\n",
    "rmse = mean_squared_error(all_pred, all_gt, squared = False)\n",
    "# f1 = f1_score(all_pred, all_gt)\n",
    "print(f'all | rmse: {\"%.3f\" % rmse}')\n",
    "for gt in [0, 0.1, 0.5, 0.9, 1]:\n",
    "    idx = np.array(all_gt) == gt\n",
    "    if idx.any():\n",
    "        print(f'ground truth: {gt} | prediction std: {\"%.3f\" % np.std(np.array(all_pred)[idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76964648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL -> SL\n",
      "A30 | rmse: 0.028\n",
      "A35 | rmse: 0.016\n",
      "A40 | rmse: 0.017\n",
      "A45 | rmse: 0.008\n",
      "A50 | rmse: 0.014\n",
      "B30 | rmse: 0.037\n",
      "B35 | rmse: 0.021\n",
      "B40 | rmse: 0.014\n",
      "B45 | rmse: 0.011\n",
      "B50 | rmse: 0.008\n",
      "C30 | rmse: 0.036\n",
      "C35 | rmse: 0.018\n",
      "C40 | rmse: 0.011\n",
      "C45 | rmse: 0.007\n",
      "C50 | rmse: 0.009\n",
      "all | rmse: 0.019\n"
     ]
    }
   ],
   "source": [
    "# Intra-dataset prediction\n",
    "print('SL -> SL')\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "np_x, np_y,_, df_meta = load_datasets(datasets_SL)\n",
    "idx = np.arange(np_y.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "np_x = np_x[:, idx]\n",
    "np_y = np_y[idx]\n",
    "df_meta = df_meta.iloc[idx]\n",
    "outlier_pipeline.fit(np_x.T)\n",
    "pred_dict = defaultdict(lambda : [])\n",
    "gt_dict = defaultdict(lambda : [])\n",
    "k_fold = KFold(n_splits=5)\n",
    "for trainidx, testidx in k_fold.split(np_x.T):\n",
    "    train_x = np_x[:, trainidx]\n",
    "    train_y = np_y[trainidx]\n",
    "    test_x = np_x[:, testidx]\n",
    "    test_y = np_y[testidx]\n",
    "    df_test = df_meta.iloc[testidx]\n",
    "    train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "    test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "    # outlier detection for training set\n",
    "    W_x = outlier_pipeline.transform(train_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, train_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    idx = weight_x > train_threshold\n",
    "    train_x = W_x[idx,:]\n",
    "    train_y = train_y[idx]\n",
    "    # outlier detection for test set\n",
    "    W_x = outlier_pipeline.transform(test_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, test_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    clip = weight_x > test_threshold\n",
    "    test_x = W_x[clip,:]\n",
    "    test_y = test_y[clip]\n",
    "    if ~clip.all():\n",
    "        print(f'{df_test[~clip]} is removed')\n",
    "    df_test = df_test.iloc[clip]\n",
    "    regressor_pipeline.fit(train_x, scalery.fit_transform(train_y.reshape((-1,1))).reshape(-1))\n",
    "    pred = np.clip(scalery.inverse_transform(regressor_pipeline.predict(test_x).reshape((-1,1))), 0, 1)\n",
    "    for i in range(pred.shape[0]):\n",
    "        key = df_test.iloc[i][0] + str(df_test.iloc[i][2])\n",
    "        pred_dict[key].append(pred[i])\n",
    "        gt_dict[key].append(test_y[i])\n",
    "isolation_window = ['A', 'B', 'C']\n",
    "energy_level = [30 , 35, 40, 45, 50]\n",
    "all_pred = []\n",
    "all_gt = []\n",
    "for (i, iw) in enumerate(isolation_window):\n",
    "    for (j, el) in enumerate(energy_level):\n",
    "        key = iw + str(el)\n",
    "        rmse = mean_squared_error(pred_dict[key], gt_dict[key], squared=False)\n",
    "        # f1 = f1_score(pred_dict[key], gt_dict[key])\n",
    "        print(f'{iw}{el} | rmse: {\"%.3f\" % rmse}')\n",
    "        all_pred = all_pred + pred_dict[key]\n",
    "        all_gt = all_gt + gt_dict[key]\n",
    "\n",
    "rmse = mean_squared_error(all_pred, all_gt, squared = False)\n",
    "# f1 = f1_score(all_pred, all_gt)\n",
    "print(f'all | rmse: {\"%.3f\" % rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c39a5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIST -> NIST\n",
      "   0    1   2             3              4     5\n",
      "3  A  CID  45  G2FS2(6)_MS5  G2FS2(6)_REDO  NIST is removed\n",
      "    0    1   2             3              4     5\n",
      "7   B  CID  40  G2FS2(6)_MS5  G2FS2(6)_REDO  NIST\n",
      "10  C  CID  30  G2FS2(6)_MS5  G2FS2(6)_REDO  NIST\n",
      "2   A  CID  40  G2FS2(6)_MS5  G2FS2(6)_REDO  NIST\n",
      "12  C  CID  40  G2FS2(6)_MS5  G2FS2(6)_REDO  NIST is removed\n",
      "    0    1   2             3              4     5\n",
      "1   A  CID  35  G2FS2(6)_MS5  G2FS2(6)_REDO  NIST\n",
      "14  C  CID  50  G2FS2(6)_MS5  G2FS2(6)_REDO  NIST is removed\n",
      "A30 | rmse: 0.024\n",
      "A35 | rmse: 0.046\n",
      "A40 | rmse: 0.033\n",
      "A45 | rmse: 0.022\n",
      "A50 | rmse: 0.158\n",
      "B30 | rmse: 0.063\n",
      "B35 | rmse: 0.083\n",
      "B40 | rmse: 0.023\n",
      "B45 | rmse: 0.024\n",
      "B50 | rmse: 0.069\n",
      "C30 | rmse: 0.050\n",
      "C35 | rmse: 0.120\n",
      "C40 | rmse: 0.003\n",
      "C45 | rmse: 0.037\n",
      "C50 | rmse: 0.040\n",
      "all | rmse: 0.068\n"
     ]
    }
   ],
   "source": [
    "# Intra-dataset prediction\n",
    "print('NIST -> NIST')\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "np_x, np_y,_, df_meta = load_datasets(datasets_NIST_train)\n",
    "idx = np.arange(np_y.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "np_x = np_x[:, idx]\n",
    "np_y = np_y[idx]\n",
    "df_meta = df_meta.iloc[idx]\n",
    "outlier_pipeline.fit(np_x.T)\n",
    "pred_dict = defaultdict(lambda : [])\n",
    "gt_dict = defaultdict(lambda : [])\n",
    "k_fold = KFold(n_splits=5)\n",
    "for trainidx, testidx in k_fold.split(np_x.T):\n",
    "    train_x = np_x[:, trainidx]\n",
    "    train_y = np_y[trainidx]\n",
    "    test_x = np_x[:, testidx]\n",
    "    test_y = np_y[testidx]\n",
    "    df_test = df_meta.iloc[testidx]\n",
    "    train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "    test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "    # outlier detection for training set\n",
    "    # outlier_pipeline.fit(train_x.T)\n",
    "    W_x = outlier_pipeline.transform(train_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, train_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    idx = weight_x > train_threshold\n",
    "    train_x = W_x[idx,:]\n",
    "    train_y = train_y[idx]\n",
    "    # outlier detection for test set\n",
    "    W_x = outlier_pipeline.transform(test_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, test_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    clip = weight_x > test_threshold\n",
    "    if ~clip.all():\n",
    "        print(f'{df_test[~clip]} is removed')\n",
    "    test_x = W_x[clip,:]\n",
    "    test_y = test_y[clip]\n",
    "    df_test = df_test.iloc[clip]\n",
    "    regressor_pipeline.fit(train_x, scalery.fit_transform(train_y.reshape((-1,1))).reshape(-1))\n",
    "    pred = np.clip(scalery.inverse_transform(regressor_pipeline.predict(test_x).reshape((-1,1))), 0, 1)\n",
    "    for i in range(pred.shape[0]):\n",
    "        key = df_test.iloc[i][0] + str(df_test.iloc[i][2])\n",
    "        pred_dict[key].append(pred[i])\n",
    "        gt_dict[key].append(test_y[i])\n",
    "isolation_window = ['A', 'B', 'C']\n",
    "energy_level = [30 , 35, 40, 45, 50]\n",
    "all_pred = []\n",
    "all_gt = []\n",
    "for (i, iw) in enumerate(isolation_window):\n",
    "    for (j, el) in enumerate(energy_level):\n",
    "        key = iw + str(el)\n",
    "        rmse = mean_squared_error(pred_dict[key], gt_dict[key], squared=False)\n",
    "        # f1 = f1_score(pred_dict[key], gt_dict[key])\n",
    "        print(f'{iw}{el} | rmse: {\"%.3f\" % rmse}')\n",
    "        all_pred = all_pred + pred_dict[key]\n",
    "        all_gt = all_gt + gt_dict[key]\n",
    "\n",
    "rmse = mean_squared_error(all_pred, all_gt, squared = False)\n",
    "# f1 = f1_score(all_pred, all_gt)\n",
    "print(f'all | rmse: {\"%.3f\" % rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2773eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all -> all\n",
      "A30 | rmse: 0.028\n",
      "A35 | rmse: 0.043\n",
      "A40 | rmse: 0.025\n",
      "A45 | rmse: 0.037\n",
      "A50 | rmse: 0.105\n",
      "B30 | rmse: 0.050\n",
      "B35 | rmse: 0.055\n",
      "B40 | rmse: 0.037\n",
      "B45 | rmse: 0.061\n",
      "B50 | rmse: 0.036\n",
      "C30 | rmse: 0.046\n",
      "C35 | rmse: 0.079\n",
      "C40 | rmse: 0.021\n",
      "C45 | rmse: 0.023\n",
      "C50 | rmse: 0.037\n",
      "all | rmse: 0.051\n"
     ]
    }
   ],
   "source": [
    "# Intra-dataset prediction\n",
    "print('all -> all')\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "np_x, np_y,_, df_meta = load_datasets(datasets_SL+datasets_NIST)\n",
    "idx = np.arange(np_y.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "np_x = np_x[:, idx]\n",
    "np_y = np_y[idx]\n",
    "df_meta = df_meta.iloc[idx]\n",
    "outlier_pipeline.fit(np_x.T)\n",
    "pred_dict = defaultdict(lambda : [])\n",
    "gt_dict = defaultdict(lambda : [])\n",
    "k_fold = KFold(n_splits=5)\n",
    "for trainidx, testidx in k_fold.split(np_x.T):\n",
    "    train_x = np_x[:, trainidx]\n",
    "    train_y = np_y[trainidx]\n",
    "    test_x = np_x[:, testidx]\n",
    "    test_y = np_y[testidx]\n",
    "    df_test = df_meta.iloc[testidx]\n",
    "    train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "    test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "    # outlier detection for training set\n",
    "    # outlier_pipeline.fit(train_x.T)\n",
    "    W_x = outlier_pipeline.transform(train_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, train_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    idx = weight_x > train_threshold\n",
    "    train_x = W_x[idx,:]\n",
    "    train_y = train_y[idx]\n",
    "    # outlier detection for test set\n",
    "    W_x = outlier_pipeline.transform(test_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, test_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    clip = weight_x > test_threshold\n",
    "    test_x = W_x[clip,:]\n",
    "    test_y = test_y[clip]\n",
    "    df_test = df_test.iloc[clip]\n",
    "    regressor_pipeline.fit(train_x, scalery.fit_transform(train_y.reshape((-1,1))).reshape(-1))\n",
    "    pred = np.clip(scalery.inverse_transform(regressor_pipeline.predict(test_x).reshape((-1,1))), 0, 1)\n",
    "    for i in range(pred.shape[0]):\n",
    "        key = df_test.iloc[i][0] + str(df_test.iloc[i][2])\n",
    "        pred_dict[key].append(pred[i])\n",
    "        gt_dict[key].append(test_y[i])\n",
    "isolation_window = ['A', 'B', 'C']\n",
    "energy_level = [30 , 35, 40, 45, 50]\n",
    "all_pred = []\n",
    "all_gt = []\n",
    "for (i, iw) in enumerate(isolation_window):\n",
    "    for (j, el) in enumerate(energy_level):\n",
    "        key = iw + str(el)\n",
    "        rmse = mean_squared_error(pred_dict[key], gt_dict[key], squared=False)\n",
    "        # f1 = f1_score(pred_dict[key], gt_dict[key])\n",
    "        print(f'{iw}{el} | rmse: {\"%.3f\" % rmse}')\n",
    "        all_pred = all_pred + pred_dict[key]\n",
    "        all_gt = all_gt + gt_dict[key]\n",
    "\n",
    "rmse = mean_squared_error(all_pred, all_gt, squared = False)\n",
    "# f1 = f1_score(all_pred, all_gt)\n",
    "print(f'all | rmse: {\"%.3f\" % rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f38f2235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set samples:168 test set samples:45\n",
      "26.6(87.7)\n",
      "17.1(80.7)\n",
      "37.2(85.6)\n",
      "14.9(90.5)\n",
      "37.3(92.8)\n",
      "52.6(48.2)\n",
      "0.4(96.6)\n",
      "7.6(94.2)\n",
      "29.7(97.4)\n",
      "10.7(88.3)\n",
      "28.2(78.1)\n",
      "20.3(90.6)\n",
      "6.3(91.6)\n",
      "3.1(96.4)\n",
      "10.3(94.8)\n",
      "\n",
      "\n",
      "0.0(96.9)\n",
      "0.8(95.1)\n",
      "0.8(92.8)\n",
      "0.0(97.0)\n",
      "0.0(95.7)\n",
      "0.0(96.6)\n",
      "0.0(94.8)\n",
      "1.4(94.9)\n",
      "0.0(96.4)\n",
      "0.0(94.2)\n",
      "0.0(98.9)\n",
      "0.0(98.1)\n",
      "2.2(96.2)\n",
      "0.0(97.0)\n",
      "0.0(96.1)\n",
      "\n",
      "\n",
      "28.4(69.7)\n",
      "11.8(88.3)\n",
      "19.7(75.5)\n",
      "1.5(93.0)\n",
      "55.5(71.5)\n",
      "41.2(76.6)\n",
      "77.4(63.8)\n",
      "38.8(72.1)\n",
      "28.3(68.2)\n",
      "41.6(59.6)\n",
      "80.7(49.5)\n",
      "33.4(64.0)\n",
      "6.4(86.3)\n",
      "53.1(52.6)\n",
      "6.7(87.9)\n",
      "\n",
      "\n",
      "ControlFetuin: 0.17043528080239712 0.11908539085888523\n",
      "ControlTransferrin: 0.003445663724436439 0.006442280269116711\n",
      "Alpha.2,3Neur.Fetuin: 0.06575510638895406 0.036375400569296605\n"
     ]
    }
   ],
   "source": [
    "# Predict released glycans\n",
    "test_x, test_y, _,test_meta = load_datasets(datasets_Released)\n",
    "train_x, train_y, _,train_meta = load_datasets(datasets_NIST+datasets_SL)\n",
    "clip = np.where(test_meta[1] == 'CID')[0]\n",
    "test_x = test_x[:,clip]\n",
    "test_y = test_y[clip]\n",
    "test_meta = test_meta.iloc[clip]\n",
    "scalery = StandardScaler()\n",
    "train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "# outlier detection for training set\n",
    "outlier_pipeline.fit(np.concatenate((train_x.T, test_x.T)))\n",
    "W_x = outlier_pipeline.transform(train_x.T)\n",
    "est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "cs_x = cosine_similarity(est_x, train_x.T)\n",
    "weight_x = cs_x.diagonal()\n",
    "idx = weight_x > train_threshold\n",
    "train_x = W_x[idx,:]\n",
    "train_y = train_y[idx]\n",
    "train_meta = train_meta.iloc[idx]\n",
    "# outlier detection for test set\n",
    "W_x = outlier_pipeline.transform(test_x.T)\n",
    "est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "cs_x = cosine_similarity(est_x, test_x.T)\n",
    "weight_x = cs_x.diagonal()\n",
    "clip = weight_x > 0\n",
    "test_x = W_x[clip,:]\n",
    "test_y = test_y[clip]\n",
    "test_meta = test_meta.iloc[clip]\n",
    "model = regressor_pipeline.fit(train_x, scalery.fit_transform(train_y.reshape((-1,1))).reshape(-1))\n",
    "print(f'training set samples:{train_x.shape[0]} test set samples:{test_x.shape[0]}')\n",
    "pred_dict = defaultdict(lambda : [])\n",
    "pred = np.clip(scalery.inverse_transform(model.predict(test_x).reshape((-1,1))), 0, 1)\n",
    "for i in range(len(test_meta)):\n",
    "    print(f'{\"%.1f\" % (100*pred[i])}({\"%.1f\" % (100*weight_x[i])})')\n",
    "    if (i+1) % 15 == 0:\n",
    "        print('\\n')\n",
    "    if weight_x[i] > test_threshold:\n",
    "        # print(test_meta.iloc[i][4])\n",
    "        pred_dict[test_meta.iloc[i][4]].append(pred[i])\n",
    "for key in pred_dict.keys():\n",
    "    print(f'{key}: {np.mean(pred_dict[key])} {np.std(pred_dict[key])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5193a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isolation_window</th>\n",
       "      <th>instrument</th>\n",
       "      <th>collision_energy</th>\n",
       "      <th>ratio</th>\n",
       "      <th>glycan_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>quality_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>35</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.720166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>40</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.704256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>50</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.742414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>30</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>50</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.683916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>40</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>45</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>50</td>\n",
       "      <td>G2FS26_MS5</td>\n",
       "      <td>G2FS2(6)</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>35</td>\n",
       "      <td>G2FS2(6)_MS5</td>\n",
       "      <td>G2FS2(6)_REDO</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.570558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>40</td>\n",
       "      <td>G2FS2(6)_MS5</td>\n",
       "      <td>G2FS2(6)_REDO</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.782714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>45</td>\n",
       "      <td>G2FS2(6)_MS5</td>\n",
       "      <td>G2FS2(6)_REDO</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.653770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>40</td>\n",
       "      <td>G2FS2(6)_MS5</td>\n",
       "      <td>G2FS2(6)_REDO</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.706048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>30</td>\n",
       "      <td>G2FS2(6)_MS5</td>\n",
       "      <td>G2FS2(6)_REDO</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.725241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>40</td>\n",
       "      <td>G2FS2(6)_MS5</td>\n",
       "      <td>G2FS2(6)_REDO</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.795995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>50</td>\n",
       "      <td>G2FS2(6)_MS5</td>\n",
       "      <td>G2FS2(6)_REDO</td>\n",
       "      <td>NIST</td>\n",
       "      <td>0.790825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>30</td>\n",
       "      <td>FETUINMS5</td>\n",
       "      <td>ControlFetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.512183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>30</td>\n",
       "      <td>FETUINMS5</td>\n",
       "      <td>ControlFetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.776537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>30</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.699099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>40</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.768336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>A</td>\n",
       "      <td>CID</td>\n",
       "      <td>50</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.747789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>30</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.778605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>35</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.695070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>40</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.720642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>45</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.707399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>B</td>\n",
       "      <td>CID</td>\n",
       "      <td>50</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.609630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>30</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.524699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>35</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.642686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>C</td>\n",
       "      <td>CID</td>\n",
       "      <td>45</td>\n",
       "      <td>959_MS5</td>\n",
       "      <td>Alpha.2,3Neur.Fetuin</td>\n",
       "      <td>UGA-R</td>\n",
       "      <td>0.541232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    isolation_window instrument  collision_energy         ratio  \\\n",
       "46                 A        CID                35    G2FS26_MS5   \n",
       "47                 A        CID                40    G2FS26_MS5   \n",
       "49                 A        CID                50    G2FS26_MS5   \n",
       "50                 B        CID                30    G2FS26_MS5   \n",
       "54                 B        CID                50    G2FS26_MS5   \n",
       "57                 C        CID                40    G2FS26_MS5   \n",
       "58                 C        CID                45    G2FS26_MS5   \n",
       "59                 C        CID                50    G2FS26_MS5   \n",
       "61                 A        CID                35  G2FS2(6)_MS5   \n",
       "62                 A        CID                40  G2FS2(6)_MS5   \n",
       "63                 A        CID                45  G2FS2(6)_MS5   \n",
       "67                 B        CID                40  G2FS2(6)_MS5   \n",
       "70                 C        CID                30  G2FS2(6)_MS5   \n",
       "72                 C        CID                40  G2FS2(6)_MS5   \n",
       "74                 C        CID                50  G2FS2(6)_MS5   \n",
       "110                B        CID                30     FETUINMS5   \n",
       "115                C        CID                30     FETUINMS5   \n",
       "135                A        CID                30       959_MS5   \n",
       "137                A        CID                40       959_MS5   \n",
       "139                A        CID                50       959_MS5   \n",
       "140                B        CID                30       959_MS5   \n",
       "141                B        CID                35       959_MS5   \n",
       "142                B        CID                40       959_MS5   \n",
       "143                B        CID                45       959_MS5   \n",
       "144                B        CID                50       959_MS5   \n",
       "145                C        CID                30       959_MS5   \n",
       "146                C        CID                35       959_MS5   \n",
       "148                C        CID                45       959_MS5   \n",
       "\n",
       "              glycan_type dataset  quality_score  \n",
       "46               G2FS2(6)    NIST       0.720166  \n",
       "47               G2FS2(6)    NIST       0.704256  \n",
       "49               G2FS2(6)    NIST       0.742414  \n",
       "50               G2FS2(6)    NIST       0.000000  \n",
       "54               G2FS2(6)    NIST       0.683916  \n",
       "57               G2FS2(6)    NIST       0.113300  \n",
       "58               G2FS2(6)    NIST       0.000000  \n",
       "59               G2FS2(6)    NIST       0.000000  \n",
       "61          G2FS2(6)_REDO    NIST       0.570558  \n",
       "62          G2FS2(6)_REDO    NIST       0.782714  \n",
       "63          G2FS2(6)_REDO    NIST       0.653770  \n",
       "67          G2FS2(6)_REDO    NIST       0.706048  \n",
       "70          G2FS2(6)_REDO    NIST       0.725241  \n",
       "72          G2FS2(6)_REDO    NIST       0.795995  \n",
       "74          G2FS2(6)_REDO    NIST       0.790825  \n",
       "110         ControlFetuin   UGA-R       0.512183  \n",
       "115         ControlFetuin   UGA-R       0.776537  \n",
       "135  Alpha.2,3Neur.Fetuin   UGA-R       0.699099  \n",
       "137  Alpha.2,3Neur.Fetuin   UGA-R       0.768336  \n",
       "139  Alpha.2,3Neur.Fetuin   UGA-R       0.747789  \n",
       "140  Alpha.2,3Neur.Fetuin   UGA-R       0.778605  \n",
       "141  Alpha.2,3Neur.Fetuin   UGA-R       0.695070  \n",
       "142  Alpha.2,3Neur.Fetuin   UGA-R       0.720642  \n",
       "143  Alpha.2,3Neur.Fetuin   UGA-R       0.707399  \n",
       "144  Alpha.2,3Neur.Fetuin   UGA-R       0.609630  \n",
       "145  Alpha.2,3Neur.Fetuin   UGA-R       0.524699  \n",
       "146  Alpha.2,3Neur.Fetuin   UGA-R       0.642686  \n",
       "148  Alpha.2,3Neur.Fetuin   UGA-R       0.541232  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List outliers\n",
    "train_meta[train_meta['quality_score'] < 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac630500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103.05746563 117.06026591 131.07766765 141.06506639 143.08006789\n",
      " 145.09506939 173.11527141 175.13027291]\n"
     ]
    }
   ],
   "source": [
    "# detect peaks in basis spectra\n",
    "import scipy.signal as signal\n",
    "test_x, test_y, _,test_meta = load_datasets(datasets_NIST_old, 'NMF_template')\n",
    "train_x, train_y, mass_features,train_meta = load_datasets(datasets_SL)\n",
    "scalery = StandardScaler()\n",
    "train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "# outlier detection for training set\n",
    "outlier_pipeline.fit(np.concatenate((train_x.T, test_x.T)))\n",
    "W_x = outlier_pipeline.transform(train_x.T)\n",
    "# detect W_x peaks\n",
    "H = outlier_pipeline.steps[0][1].components_\n",
    "H_sum = H[0,:]/np.max(H[0,:]) + H[1,:]/np.max(H[1,:])\n",
    "peaks,_ = signal.find_peaks(H_sum, height=0.1, distance = 68)\n",
    "mz_peaks = mass_features[peaks]\n",
    "print(mz_peaks)\n",
    "mass_tol = 33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f1628a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19d4a841460>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(mass_features,H[1,:]/np.max(H[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7398a5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked peak: 103.05746563092\n",
      "training set samples:78 test set samples:73\n",
      "-0.009(78.33%)\n",
      "0.048(211.48%)\n",
      "0.006(113.01%)\n",
      "-0.010(77.51%)\n",
      "0.034(179.84%)\n",
      "0.011(126.56%)\n",
      "0.082(290.91%)\n",
      "-0.029(31.89%)\n",
      "-0.043(0.00%)\n",
      "0.004(110.25%)\n",
      "0.044(201.89%)\n",
      "0.069(262.38%)\n",
      "-0.040(5.94%)\n",
      "0.009(121.77%)\n",
      "-0.022(48.78%)\n",
      "all | rmse: 0.066 | avg diff:0.010\n",
      "masked peak: 117.060265910948\n",
      "training set samples:78 test set samples:73\n",
      "0.196(558.16%)\n",
      "0.301(804.27%)\n",
      "0.141(429.38%)\n",
      "0.114(366.21%)\n",
      "0.188(541.07%)\n",
      "0.081(288.90%)\n",
      "0.422(1087.63%)\n",
      "0.112(362.72%)\n",
      "0.015(134.21%)\n",
      "0.211(593.65%)\n",
      "0.244(671.85%)\n",
      "0.267(724.21%)\n",
      "0.070(263.18%)\n",
      "0.164(484.85%)\n",
      "0.172(501.94%)\n",
      "all | rmse: 0.250 | avg diff:0.180\n",
      "masked peak: 131.077667651122\n",
      "training set samples:78 test set samples:73\n",
      "-0.043(0.00%)\n",
      "-0.032(25.75%)\n",
      "-0.010(77.17%)\n",
      "-0.029(31.93%)\n",
      "-0.026(38.10%)\n",
      "-0.043(0.00%)\n",
      "0.070(263.73%)\n",
      "-0.043(0.00%)\n",
      "-0.043(0.00%)\n",
      "0.001(103.15%)\n",
      "0.005(112.25%)\n",
      "0.084(296.65%)\n",
      "-0.043(0.00%)\n",
      "-0.007(84.61%)\n",
      "-0.043(0.00%)\n",
      "all | rmse: 0.051 | avg diff:-0.013\n",
      "masked peak: 141.065066390996\n",
      "training set samples:78 test set samples:73\n",
      "-0.001(98.46%)\n",
      "0.060(240.87%)\n",
      "0.010(123.68%)\n",
      "-0.004(91.60%)\n",
      "0.044(203.55%)\n",
      "0.017(139.56%)\n",
      "0.086(300.66%)\n",
      "-0.024(42.85%)\n",
      "-0.043(0.00%)\n",
      "0.012(128.22%)\n",
      "0.049(213.56%)\n",
      "0.068(258.97%)\n",
      "-0.031(26.40%)\n",
      "0.017(140.93%)\n",
      "-0.009(78.51%)\n",
      "all | rmse: 0.071 | avg diff:0.017\n",
      "masked peak: 143.080067891146\n",
      "training set samples:78 test set samples:73\n",
      "-0.004(89.90%)\n",
      "0.052(221.52%)\n",
      "0.014(133.67%)\n",
      "-0.006(86.46%)\n",
      "0.039(190.79%)\n",
      "0.001(101.79%)\n",
      "0.092(314.99%)\n",
      "-0.026(38.62%)\n",
      "-0.039(9.18%)\n",
      "0.014(133.86%)\n",
      "0.037(186.86%)\n",
      "0.067(257.85%)\n",
      "-0.029(31.96%)\n",
      "0.023(152.87%)\n",
      "-0.006(85.01%)\n",
      "all | rmse: 0.070 | avg diff:0.015\n",
      "masked peak: 145.095069391296\n",
      "training set samples:78 test set samples:73\n",
      "-0.000(98.98%)\n",
      "0.060(241.29%)\n",
      "0.010(124.11%)\n",
      "-0.003(92.53%)\n",
      "0.044(203.96%)\n",
      "0.017(139.90%)\n",
      "0.087(302.58%)\n",
      "-0.024(43.64%)\n",
      "-0.040(5.23%)\n",
      "0.012(129.20%)\n",
      "0.049(213.87%)\n",
      "0.068(258.79%)\n",
      "-0.031(26.73%)\n",
      "0.018(141.45%)\n",
      "-0.008(81.08%)\n",
      "all | rmse: 0.071 | avg diff:0.017\n",
      "masked peak: 173.115271411498\n",
      "training set samples:78 test set samples:73\n",
      "-0.001(98.16%)\n",
      "0.018(141.67%)\n",
      "0.002(105.21%)\n",
      "-0.005(87.69%)\n",
      "0.036(183.42%)\n",
      "0.013(129.72%)\n",
      "0.042(197.49%)\n",
      "-0.020(52.10%)\n",
      "-0.036(15.72%)\n",
      "-0.009(78.81%)\n",
      "0.034(178.72%)\n",
      "0.026(161.36%)\n",
      "-0.028(34.97%)\n",
      "0.009(121.33%)\n",
      "-0.018(57.58%)\n",
      "all | rmse: 0.052 | avg diff:0.004\n",
      "masked peak: 175.130272911648\n",
      "training set samples:78 test set samples:73\n",
      "-0.003(92.40%)\n",
      "0.110(356.29%)\n",
      "0.023(154.12%)\n",
      "-0.003(92.39%)\n",
      "0.086(300.81%)\n",
      "0.042(198.67%)\n",
      "0.082(291.63%)\n",
      "-0.025(41.48%)\n",
      "-0.035(17.57%)\n",
      "0.009(120.11%)\n",
      "0.044(203.80%)\n",
      "0.035(181.35%)\n",
      "-0.021(51.83%)\n",
      "0.042(198.25%)\n",
      "0.000(100.61%)\n",
      "all | rmse: 0.080 | avg diff:0.026\n"
     ]
    }
   ],
   "source": [
    "# mask each peak and see the influence on the prediction\n",
    "for masked_peak in mz_peaks:\n",
    "    print(f'masked peak: {masked_peak}')\n",
    "    test_x, test_y, _,test_meta = load_datasets(datasets_NIST_old, 'NMF_template')\n",
    "    train_x, train_y, _,train_meta = load_datasets(datasets_SL)\n",
    "    mass_tol = 0.5\n",
    "    mask = np.where((mass_features > masked_peak-mass_tol) & (mass_features < masked_peak+mass_tol))[0]\n",
    "    train_x[mask,:] = 0\n",
    "    test_x[mask,:] = 0\n",
    "    scalery = StandardScaler()\n",
    "    train_x = preprocessing_pipeline.fit_transform(train_x.T).T\n",
    "    test_x = preprocessing_pipeline.transform(test_x.T).T\n",
    "    # outlier detection for training set\n",
    "    outlier_pipeline.fit(np.concatenate((train_x.T, test_x.T)))\n",
    "    W_x = outlier_pipeline.transform(train_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, train_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    idx = SL_NIST_train_idx\n",
    "    train_x = W_x[idx,:]\n",
    "    train_y = train_y[idx]\n",
    "    train_meta = train_meta.iloc[idx]\n",
    "    # outlier detection for test set\n",
    "    W_x = outlier_pipeline.transform(test_x.T)\n",
    "    est_x = outlier_pipeline.inverse_transform(W_x)\n",
    "    cs_x = cosine_similarity(est_x, test_x.T)\n",
    "    weight_x = cs_x.diagonal()\n",
    "    clip = SL_NIST_test_idx\n",
    "    test_x = W_x[clip,:]\n",
    "    test_y = test_y[clip]\n",
    "    test_meta = test_meta.iloc[clip]\n",
    "    model = regressor_pipeline.fit(train_x, scalery.fit_transform(train_y.reshape((-1,1))).reshape(-1))\n",
    "    print(f'training set samples:{train_x.shape[0]} test set samples:{test_x.shape[0]}')\n",
    "    from collections import defaultdict\n",
    "    pred_dict = defaultdict(lambda : [])\n",
    "    gt_dict = defaultdict(lambda : [])\n",
    "    pred = np.clip(scalery.inverse_transform(model.predict(test_x).reshape((-1,1))), 0, 1)\n",
    "    for i in range(pred.shape[0]):\n",
    "        key = test_meta.iloc[i][0] + str(test_meta.iloc[i][2])\n",
    "        pred_dict[key].append(pred[i])\n",
    "        gt_dict[key].append(test_y[i])\n",
    "    isolation_window = ['A', 'B', 'C']\n",
    "    energy_level = [30 , 35, 40, 45, 50]\n",
    "    all_pred = []\n",
    "    all_gt = []\n",
    "    idx = 0\n",
    "    diffs = []\n",
    "    for (i, iw) in enumerate(isolation_window):\n",
    "        for (j, el) in enumerate(energy_level):\n",
    "            key = iw + str(el)\n",
    "            # print(key)\n",
    "            rmse = mean_squared_error(pred_dict[key], gt_dict[key], squared=False)\n",
    "            s = ''\n",
    "            if rmse > SL_NIST_rmse[idx]:\n",
    "                s = '↑'\n",
    "            else:\n",
    "                s = '↓'\n",
    "            relative = \"%.2f\" % (rmse/SL_NIST_rmse[idx] * 100) + '%'\n",
    "            # f1 = f1_score(pred_dict[key], gt_dict[key])\n",
    "            diffs.append(rmse-SL_NIST_rmse[idx])\n",
    "            # print(f'{iw}{el} | rmse: {\"%.3f\" % rmse} | diff:{\"%.3f\" % (rmse-SL_NIST_rmse[idx])} {s}')\n",
    "            print(f'{\"%.3f\" % (rmse-SL_NIST_rmse[idx])}({relative})', end='\\n')\n",
    "            all_pred = all_pred + pred_dict[key]\n",
    "            all_gt = all_gt + gt_dict[key]\n",
    "\n",
    "    rmse = mean_squared_error(all_pred, all_gt, squared = False)\n",
    "    # f1 = f1_score(all_pred, all_gt)\n",
    "    print(f'all | rmse: {\"%.3f\" % rmse} | avg diff:{\"%.3f\" % np.mean(diffs)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c94720f1ee12f9a4618c3d9583909b4541447107332f796da3f36c223a9552d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
